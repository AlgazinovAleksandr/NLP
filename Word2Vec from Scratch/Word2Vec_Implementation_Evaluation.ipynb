{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQnk0ZB-bivS"
      },
      "source": [
        "# Word2Vec: training from scratch, evaluation, and comparison with the pre-trained LLM from HuggingFace\n",
        "\n",
        "**Initially, this was a home assignment for one of my NLP courses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNMWXfkwbivU"
      },
      "source": [
        "# 1 Word2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvX2WY_abivV"
      },
      "source": [
        "### 1.1 Word2Vec Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syjSYZPPbivV"
      },
      "source": [
        "##### Motivation for choosing Skig-gram:\n",
        "\n",
        "+ **Makes more sense**: in a Skip-gram model, we predict the context given the center (target word). Hence, we learn to optimize the target's word embedding to capture all the contexts it appears in. CBOW, on the other hand, optimizes the average of context words to predict the target word. Based on the common sense and the task definition (map an arbitraty word to a high-quality vector representation), Skip-gram model results in a highter quality embeddings.\n",
        "\n",
        "+ **Simpler input format**: in a Skip-gram model, a training example is a (target, context) pair. Hence, for example, if the window size is 2, there will be 4 pairs for the single observation. In case of CBOW, one pair will look like ([context_-2, context_-1, context_1, context_2], target), after which the context word will be combined to a single vector (averaging is the simple and the standard way). Seems like the Skip-gram model provides a more simple way to do it.\n",
        "\n",
        "Even though Skip-gram is considered to be comptutationally heavier, resulting in a slower training, I still think it is more suitable for this assignment. I do not think that our goal is to reach a perfect-quality model. Hence, we can stop the training process even before we achieve a very good quality"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-wpWIDbbivV"
      },
      "source": [
        "##### Downloading and cleaning the data\n",
        "\n",
        "We will take one file from the website with the Wikipedia data. Firstly, we will convert it to a readable format by removing most of the unnecessary information provided in the original file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kSVI_P2-bivV",
        "outputId": "8b530a72-4c17-4395-c952-1d700e94f6ad"
      },
      "outputs": [],
      "source": [
        "from gensim.corpora import WikiCorpus\n",
        "\n",
        "def extract_text(input_xml, output_txt):\n",
        "    wiki = WikiCorpus(input_xml, dictionary={})\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        for text in wiki.get_texts():\n",
        "            f.write(' '.join(text) + '\\n')  # One article per line\n",
        "\n",
        "extract_text('enwiki-some-pages-articles.xml.bz2', 'wiki_text.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90nl4g6fbivX"
      },
      "source": [
        "This results in a pre-processed collection of text (lowercasing, removed punctuation, some other standard things are already done). The next possible step is to do stemming / lemmatization. However, I suggest not doing it for the word maintainance purposes. If the vocabulary would turn out to be too big, we can return to this step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFrLv9dUbivX",
        "outputId": "3429fad8-7920-4ca2-b410-19322f26485b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "40721"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "MIN_COUNT = 10\n",
        "text = open('wiki_text.txt').read()\n",
        "tokens = text.split()\n",
        "word_counts = Counter(tokens)\n",
        "vocab = ['<unk>'] + [word for word, count in word_counts.items() if count >= MIN_COUNT]\n",
        "word_to_idx = {word:i for i, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S208lAsObivX"
      },
      "source": [
        "**Even with min_count = 10**, the vocabulary turns out to be quite big. Hence, perhaps lemmatization makes sense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8uo5TAQhbivX"
      },
      "outputs": [],
      "source": [
        "import spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4liyKR87bivX"
      },
      "outputs": [],
      "source": [
        "#! python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09SA4MAYbivY"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
        "\n",
        "def lemmatize_line(line):\n",
        "    doc = nlp(line)\n",
        "    lemmatized_output = ' '.join([token.lemma_ for token in doc])\n",
        "    return lemmatized_output\n",
        "\n",
        "lemmatized_lines = []\n",
        "with open('wiki_text.txt', 'r') as file:\n",
        "    for line in file:\n",
        "        lemmatized_line = lemmatize_line(line)\n",
        "        lemmatized_lines.append(lemmatized_line)\n",
        "\n",
        "with open('wiki_text_lemmatized.txt', 'w') as output_file:\n",
        "    for line in lemmatized_lines:\n",
        "        output_file.write(line + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zIJSQ5dbivY",
        "outputId": "020a201b-475a-4137-f4bc-2719f536bc2e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "35570"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "MIN_COUNT = 10\n",
        "text = open('wiki_text_lemmatized.txt').read()\n",
        "tokens = text.split()\n",
        "word_counts = Counter(tokens)\n",
        "vocab = ['<unk>'] + [word for word, count in word_counts.items() if count >= MIN_COUNT]\n",
        "word2idx = {word:i for i, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GHF8wx8YbivY"
      },
      "source": [
        "**Does not change much**. Hence, let's use the non-lemmatized version, as the sentences there are more clear. But let's make the minimal word count higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwGaNR7ZbivY",
        "outputId": "72234de9-c991-4068-fb24-8f89397ea974"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "24625"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from collections import Counter\n",
        "\n",
        "MIN_COUNT = 20\n",
        "text = open('wiki_text.txt').read()\n",
        "tokens = text.split()\n",
        "word_counts = Counter(tokens)\n",
        "vocab = ['<unk>'] + [word for word, count in word_counts.items() if count >= MIN_COUNT]\n",
        "word2idx = {word:i for i, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4UZtnObbivY"
      },
      "source": [
        "##### Time to build a dataset\n",
        "\n",
        "+ tokenizer - split words by space (since we do Word2Vec, other tokenization strategies do not really make sense)\n",
        "\n",
        "+ window_size will be equal to two (I think this is the most standard case - take 2 words before the target word, and 2 words after as the context)\n",
        "\n",
        "+ we will create a dataset.py file, which will contain the SkipGramDataset class\n",
        "\n",
        "+ hence, we will just import it and use it build the dataset\n",
        "\n",
        "+ regarding negative sampling probabilities, please read comments in the code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MOaWxsJR5jEX"
      },
      "source": [
        "**To make the model training process not so slow, it was decided to decrease the total number of documents to be processed (we will leave 80% of the initial documents)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uAWQHERnhpaA"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "# leave random keep_fraction of the initial documents (lines) in the file\n",
        "def create_cut_file(original_file, output_file, keep_fraction=0.8):\n",
        "    with open(original_file, 'r') as f:\n",
        "        all_lines = [line for line in f if line.strip()]\n",
        "\n",
        "    # Calculate number of lines to keep\n",
        "    num_lines = len(all_lines)\n",
        "    num_to_keep = int(num_lines * keep_fraction)\n",
        "\n",
        "    # Randomly sample lines\n",
        "    sampled_lines = random.sample(all_lines, num_to_keep)\n",
        "    sampled_lines.sort()\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.writelines(sampled_lines)\n",
        "\n",
        "original_file = 'wiki_text.txt'\n",
        "output_file = 'cut_text.txt'\n",
        "create_cut_file(original_file, output_file, keep_fraction=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKkRabijbivY",
        "outputId": "38f85b38-2bca-4edf-bf7a-3787538255b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21413"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dataset import SkipGramDataset\n",
        "file_path = 'cut_text.txt'  # Decided to use the non-lemmatized text\n",
        "min_count = 20\n",
        "window_size = 2\n",
        "\n",
        "dataset = SkipGramDataset(file_path, window_size=window_size, min_count=min_count)\n",
        "dataset.vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "mocKDqhJbivY"
      },
      "outputs": [],
      "source": [
        "# I was experimenting with different batch sizes\n",
        "from torch.utils.data import DataLoader\n",
        "# dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "# dataloader = DataLoader(dataset, batch_size=256, shuffle=True)\n",
        "# dataloader = DataLoader(dataset, batch_size=1024, shuffle=True)\n",
        "dataloader = DataLoader(dataset, batch_size=2048, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCLT-63lbivY"
      },
      "source": [
        "##### Train a Skip-gram model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "G1i20bthbivZ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from skipgram import SkipGramModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2IrCsHVobivZ",
        "outputId": "aa3796b6-0aec-474d-d2b7-5f00f3ab98e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: mps\n"
          ]
        }
      ],
      "source": [
        "# Either mps or cuda, depends on which device I'm currenlty using\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('Device:', device)\n",
        "\n",
        "# Initialize all three models\n",
        "model_100 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)\n",
        "model_300 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=300).to(device)\n",
        "model_500 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=500).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "zSWLYPi3kBgu"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "num_negative = 5\n",
        "learning_rate = 0.005\n",
        "\n",
        "# Training loop\n",
        "def train_model(model, model_name, num_epochs=10, save_dir='model_checkpoints'):\n",
        "  print('Model name:', model)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  for epoch in range(num_epochs):\n",
        "      total_loss = 0\n",
        "      # Wrap the dataloader with tqdm for a progress bar\n",
        "      with tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
        "          for targets, contexts in pbar:\n",
        "              targets = targets.to(device)\n",
        "              contexts = contexts.to(device)\n",
        "              optimizer.zero_grad()\n",
        "\n",
        "              # Get embeddings\n",
        "              target_emb, context_emb = model(targets, contexts)\n",
        "              pos_score = (target_emb * context_emb).sum(dim=1)  # Dot product for positive pairs\n",
        "\n",
        "              # Sample negative words\n",
        "              negative_samples = torch.multinomial(dataset.negative_sampling_probs,\n",
        "                                                targets.size(0) * num_negative,\n",
        "                                                replacement=True).view(targets.size(0), num_negative).to(device)\n",
        "              negative_emb = model.context_embeddings(negative_samples)\n",
        "              neg_scores = (target_emb.unsqueeze(1) * negative_emb).sum(dim=2)  # Dot products for negative pairs\n",
        "\n",
        "              # Compute loss\n",
        "              pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score), reduction='sum')\n",
        "              neg_loss = F.binary_cross_entropy_with_logits(neg_scores, torch.zeros_like(neg_scores), reduction='sum')\n",
        "              loss = (pos_loss + neg_loss) / targets.size(0)\n",
        "\n",
        "              # Backpropagation\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "              total_loss += loss.item()\n",
        "\n",
        "              # Update the progress bar with the current loss\n",
        "              pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "      print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "  save_path = os.path.join(save_dir, model_name)\n",
        "  torch.save(model.state_dict(), save_path)\n",
        "  print(f'Model weights saved to {save_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNZL0MuhRkf5"
      },
      "source": [
        "**To make the experiment fair, we will train each model for 10 epochs**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ALTg0Q69TI38"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "min_count = 20\n",
        "with open(file_path, 'r') as f:\n",
        "      documents = [line.strip().split() for line in f]\n",
        "      word_counts = Counter(word for doc in documents for word in doc)\n",
        "      vocab = [word for word, count in word_counts.items() if count >= min_count]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_CS6PO6IXK7Y",
        "outputId": "8b1a0376-1917-4d24-b146-bf5e6ce809ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21413"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "qJMJbk1w726Z",
        "outputId": "d70df86f-d907-4966-c43f-0eda294fcde0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>weapon</td>\n",
              "      <td>secret</td>\n",
              "      <td>2.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>weather</td>\n",
              "      <td>forecast</td>\n",
              "      <td>5.4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>Wednesday</td>\n",
              "      <td>news</td>\n",
              "      <td>1.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>wood</td>\n",
              "      <td>forest</td>\n",
              "      <td>7.9375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>word</td>\n",
              "      <td>similarity</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>353 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word 1      Word 2  Human (Mean)\n",
              "0       admission      ticket        5.5360\n",
              "1         alcohol   chemistry        4.1250\n",
              "2        aluminum       metal        6.6250\n",
              "3    announcement      effort        2.0625\n",
              "4    announcement        news        7.1875\n",
              "..            ...         ...           ...\n",
              "348        weapon      secret        2.5000\n",
              "349       weather    forecast        5.4375\n",
              "350     Wednesday        news        1.1250\n",
              "351          wood      forest        7.9375\n",
              "352          word  similarity        0.8125\n",
              "\n",
              "[353 rows x 3 columns]"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# https://www.kaggle.com/datasets/julianschelb/wordsim353-crowd\n",
        "wordsim = pd.read_csv('wordsim353crowd.csv')\n",
        "wordsim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "8qDfZMNHSLRR",
        "outputId": "0201310e-39f1-4a25-d3a1-d33e60c5267c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>weapon</td>\n",
              "      <td>secret</td>\n",
              "      <td>2.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>weather</td>\n",
              "      <td>forecast</td>\n",
              "      <td>5.4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>wednesday</td>\n",
              "      <td>news</td>\n",
              "      <td>1.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>wood</td>\n",
              "      <td>forest</td>\n",
              "      <td>7.9375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>word</td>\n",
              "      <td>similarity</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word 1      Word 2  Human (Mean)\n",
              "0       admission      ticket        5.5360\n",
              "1         alcohol   chemistry        4.1250\n",
              "2        aluminum       metal        6.6250\n",
              "3    announcement      effort        2.0625\n",
              "4    announcement        news        7.1875\n",
              "..            ...         ...           ...\n",
              "299        weapon      secret        2.5000\n",
              "300       weather    forecast        5.4375\n",
              "301     wednesday        news        1.1250\n",
              "302          wood      forest        7.9375\n",
              "303          word  similarity        0.8125\n",
              "\n",
              "[304 rows x 3 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordsim['Word 1'] = wordsim['Word 1'].str.lower()\n",
        "wordsim['Word 2'] = wordsim['Word 2'].str.lower()\n",
        "\n",
        "# Step 2: Filter rows where both words are in vocab\n",
        "wordsim = wordsim[wordsim['Word 1'].isin(vocab) & wordsim['Word 2'].isin(vocab)]\n",
        "wordsim.index = np.arange(0, len(wordsim))\n",
        "wordsim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "R1t3EnfDkKzK"
      },
      "outputs": [],
      "source": [
        "def cosine_similarity(vec1, vec2):\n",
        "    return torch.dot(vec1, vec2) / (torch.norm(vec1) * torch.norm(vec2) + 1e-8) # 1e-8 to avoid division by zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fm_VENYxkK1S"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import spearmanr\n",
        "\n",
        "def compute_correlation(model, df):\n",
        "  cosine_similarities = []\n",
        "  human_scores = []\n",
        "  for index, row in df.iterrows():\n",
        "      word1 = row['Word 1']\n",
        "      word2 = row['Word 2']\n",
        "      human_score = row['Human (Mean)']\n",
        "\n",
        "      # Get embeddings for Word 1 and Word 2\n",
        "      word_1_index = dataset.convert_word_to_idx(word1)\n",
        "      word_1_tensor = torch.tensor([word_1_index], device=device)  # Create tensor directly on the device\n",
        "      embedding1 = model.target_embeddings(word_1_tensor).squeeze(0)\n",
        "\n",
        "      word_2_index = dataset.convert_word_to_idx(word2)\n",
        "      word_2_tensor = torch.tensor([word_2_index], device=device)  # Create tensor directly on the device\n",
        "      embedding2 = model.target_embeddings(word_2_tensor).squeeze(0)\n",
        "\n",
        "\n",
        "      # Compute cosine similarity\n",
        "      similarity = cosine_similarity(embedding1, embedding2).item()  # Convert to Python float\n",
        "      cosine_similarities.append(similarity)\n",
        "      human_scores.append(human_score)\n",
        "\n",
        "  # Compute Spearman’s correlation coefficient\n",
        "  correlation, _ = spearmanr(cosine_similarities, human_scores)\n",
        "  print(f\"Spearman’s correlation coefficient: {correlation:.4f}\")\n",
        "  return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Llva9r35kK5j",
        "outputId": "a5af1aae-ba88-471b-d52e-e423b2ad51b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: SkipGramModel(\n",
            "  (target_embeddings): Embedding(21413, 100)\n",
            "  (context_embeddings): Embedding(21413, 100)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 11180/11180 [02:12<00:00, 84.54batch/s, loss=2.31] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 3.757320485110786\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 11180/11180 [02:09<00:00, 86.02batch/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 2.1817281813229132\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 11180/11180 [02:03<00:00, 90.37batch/s, loss=2.13] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 2.1177927609206524\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.73batch/s, loss=2.09] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 2.0979157258444907\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 11180/11180 [02:02<00:00, 91.54batch/s, loss=2.16] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 2.089140125741259\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.21batch/s, loss=2.06]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 2.0839818964170855\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 11180/11180 [02:07<00:00, 87.88batch/s, loss=2.13] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 2.080983997105699\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 11180/11180 [02:05<00:00, 89.29batch/s, loss=2.11] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 2.078605863659881\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.68batch/s, loss=2.11] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 2.077235227887234\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 11180/11180 [02:05<00:00, 89.25batch/s, loss=2.18]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 2.076324238184313\n",
            "Model weights saved to model_checkpoints/emb_dim_100.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model(model_100, 'emb_dim_100.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9yUfCXKI6DfW",
        "outputId": "c6d1f944-fc74-4c28-8709-38d043a7c4af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.4319\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4318654646450173"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('model_checkpoints/emb_dim_100.pt', map_location=device)\n",
        "model_100 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)\n",
        "model_100.load_state_dict(checkpoint)\n",
        "compute_correlation(model_100, wordsim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE296SUQCfeM",
        "outputId": "22d88733-5336-4db2-90f9-7eaaa9bd5ccd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: SkipGramModel(\n",
            "  (target_embeddings): Embedding(21413, 300)\n",
            "  (context_embeddings): Embedding(21413, 300)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 11180/11180 [02:43<00:00, 68.51batch/s, loss=2.85]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 6.145718262468553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 11180/11180 [02:40<00:00, 69.57batch/s, loss=2.39]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 2.4446142360434764\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 11180/11180 [02:39<00:00, 70.27batch/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 2.249341986153761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 11180/11180 [02:41<00:00, 69.07batch/s, loss=2.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 2.195541905717048\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 11180/11180 [02:37<00:00, 71.14batch/s, loss=2.16]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 2.1691580428420325\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 11180/11180 [02:40<00:00, 69.79batch/s, loss=2.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 2.1536129850181145\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 11180/11180 [02:39<00:00, 70.30batch/s, loss=2.19]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 2.1434251589297397\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 11180/11180 [02:40<00:00, 69.48batch/s, loss=2.22]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 2.1363779625653794\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 11180/11180 [02:39<00:00, 70.22batch/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 2.131725310330314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 11180/11180 [02:38<00:00, 70.71batch/s, loss=2.14]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 2.1277746795648325\n",
            "Model weights saved to model_checkpoints/emb_dim_300.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model(model_300, 'emb_dim_300.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCz1da2tCfgX",
        "outputId": "d3654879-3ae9-49b7-89c2-e563e0671a25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.4627\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4626894580061271"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('model_checkpoints/emb_dim_300.pt', map_location=device)\n",
        "model_300 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=300).to(device)\n",
        "model_300.load_state_dict(checkpoint)\n",
        "compute_correlation(model_300, wordsim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyYogsI_Cfin",
        "outputId": "741dfa8d-a788-42b7-8baa-b0334003392f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: SkipGramModel(\n",
            "  (target_embeddings): Embedding(21413, 500)\n",
            "  (context_embeddings): Embedding(21413, 500)\n",
            ")\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 11180/11180 [03:16<00:00, 56.94batch/s, loss=3.35]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 8.265202607025188\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 11180/11180 [03:16<00:00, 56.98batch/s, loss=2.82]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 2.8015666036784967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 11180/11180 [03:16<00:00, 56.89batch/s, loss=2.54]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 2.454843101646478\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 11180/11180 [03:15<00:00, 57.30batch/s, loss=2.54]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 2.370408450640165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 11180/11180 [03:14<00:00, 57.35batch/s, loss=2.31]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 2.3267650905576716\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 11180/11180 [03:18<00:00, 56.44batch/s, loss=2.38]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 2.301671056350783\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 11180/11180 [03:17<00:00, 56.66batch/s, loss=2.44]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 2.286181752626286\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 11180/11180 [03:14<00:00, 57.34batch/s, loss=2.26]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 2.27491041338721\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 11180/11180 [03:17<00:00, 56.49batch/s, loss=2.21]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 2.2668731922753595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 11180/11180 [03:15<00:00, 57.21batch/s, loss=2.39]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 2.261783000203066\n",
            "Model weights saved to model_checkpoints/emb_dim_500.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model(model_500, 'emb_dim_500.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7wMdGDAtrX1E",
        "outputId": "6a285f7c-6c76-4618-c046-64b3c1bdbe50"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.4144\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.41442795960423207"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint = torch.load('model_checkpoints/emb_dim_500.pt', map_location=device)\n",
        "model_500 = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=500).to(device)\n",
        "model_500.load_state_dict(checkpoint)\n",
        "compute_correlation(model_500, wordsim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bp4WU0tTIGs"
      },
      "source": [
        "##### Comparison\n",
        "\n",
        "As wee see, the model with embedding_dim=300 is the best in terms of quality (correlation with the human-annotated dataset). And the model with embedding_dim=500 is the worst. This result makes sense, and cab explained using the following logic:\n",
        "\n",
        "+ Not enough data for bigger models (remember the curse of dimensionality). That's why embedding_dim=500 is the worst performance We cannot handle it due to time and resource constaints\n",
        "\n",
        "+ Not enough training. Same issue as within the previous case\n",
        "\n",
        "+ Architectures with bigger embedding sizes need to be more complex (for example, several layes, activation functions, some normalizations, etc.). However, we do not want to compare different models with each other. We want to compare the same model with different amount of parameters\n",
        "\n",
        "+ Meanwhile, embedding_dim=100 might be not enough to capture the word mearnings. Hence, embedding_dim=300 might be better. For now the difference in quality is not that big (however, this is only one metric, and probably not that comprehensive and straightforward). Maybe with the increase in the number of training epochs, the difference in quality will be more significant. However, in next sections we will have to train more models, and I suggest choosing the embedding_dim=100 as the baseline (not that worse compared to the embedding_dim=300, but faster to train)\n",
        "\n",
        "Hence, for our next experiments (for example, for improvements), we will use the model with embedding_dim=100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YESQs3_NuQn"
      },
      "source": [
        "### 1.2 Word2Vec improvement\n",
        "\n",
        "Out of all the proposed methods, we will **focus on the leveraging external word knowledge sources. Motivation:**\n",
        "\n",
        "+ **Word sense disambiguation** (check https://www.geeksforgeeks.org/word-sense-disambiguation-in-natural-language-processing/ for reference), as far as I understood, is about handling words with multiple meanings by assigning different embeddings to each sense. However, this will require specific high-quality dataset (not random Wikipedia articles). Moreover, this method is about handling specific cases, while we want to improve the general quality of embeddings (given time and resource constraints)\n",
        "\n",
        "+ **Evaluating character-level embeddings** is about different tokenization (splitting text not by a space, but by a character). I do not think this makes a lot of sense in out task, since Word2Vec is Word2Vec, and it aims to convert a word to an embedding. In other tasks (like text generation) different tokenizations (like BPE) make more sense, but they also involve different neural network architectures.\n",
        "\n",
        "+ **Hence, I think that Leveraging external word knowledge sources makes the most sense in our task**. We will use WordNet to extract synonym relationships and adjust embeddings through retrofitting. It does not require retraining the model, which is good\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "jUahf1kdbivZ"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC6G_UsVbivZ",
        "outputId": "c9936415-86b0-44ba-d526-71e5416134d6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaibUuFFZxe5",
        "outputId": "5326047c-9616-4a18-a12f-4d0f86f745d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['aarhus', 'was', 'handball', 'club', 'from']"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(dataset.word_to_index.keys())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4bGXMFbZ6YE",
        "outputId": "c69acdca-f41b-4566-b02d-ddd6ecb413f2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(dataset.word_to_index.values())[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rkjgu8WsUeRK"
      },
      "outputs": [],
      "source": [
        "from nltk.corpus import wordnet as wn\n",
        "# Extract synonym pairs from WordNet\n",
        "def get_synonym_pairs(word_to_index):\n",
        "    synonym_pairs = []\n",
        "    for word in vocab:\n",
        "        synsets = wn.synsets(word)\n",
        "        for synset in synsets:\n",
        "            for lemma in synset.lemmas():\n",
        "                syn = lemma.name()\n",
        "                if syn in vocab and syn != word:\n",
        "                    # Add both directions since synonymy is symmetric\n",
        "                    synonym_pairs.append((word_to_index[word], word_to_index[syn]))\n",
        "                    synonym_pairs.append((word_to_index[syn], word_to_index[word]))\n",
        "    # Remove duplicates while preserving order\n",
        "    synonym_pairs = list(dict.fromkeys(synonym_pairs))\n",
        "    return synonym_pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSo0arZqUeTe",
        "outputId": "c774793f-50ea-40dd-af2e-869062e0909b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(1, 232), (232, 1), (1, 12559), (12559, 1), (1, 2349)]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synonym_pairs = get_synonym_pairs(dataset.word_to_index)\n",
        "synonym_pairs[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yHcqNaHPUeY9"
      },
      "outputs": [],
      "source": [
        "lambdda = 0.1  # weight for synonym loss (let it be 0.1 so that it's not too big, as I am not very sure if the method will work good)\n",
        "m = 128 # number of synonym pairs to sample per batch (I think this number is neither too big nor too small, hence, should be okay)\n",
        "\n",
        "def train_model_knowledge(model, model_name, num_epochs=10, save_dir='model_checkpoints', lambdda=lambdda, m=m):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    print(f\"Found {len(synonym_pairs)} synonym pairs from WordNet.\")\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss = 0\n",
        "        with tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}', unit='batch') as pbar:\n",
        "            for targets, contexts in pbar:\n",
        "                targets = targets.to(device)\n",
        "                contexts = contexts.to(device)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                target_emb, context_emb = model(targets, contexts)\n",
        "                pos_score = (target_emb * context_emb).sum(dim=1)  # Dot product for positive pairs\n",
        "\n",
        "                negative_samples = torch.multinomial(dataset.negative_sampling_probs,\n",
        "                                                    targets.size(0) * num_negative,\n",
        "                                                    replacement=True).view(targets.size(0), num_negative).to(device)\n",
        "                negative_emb = model.context_embeddings(negative_samples)\n",
        "                neg_scores = (target_emb.unsqueeze(1) * negative_emb).sum(dim=2)\n",
        "\n",
        "                # Original loss\n",
        "                pos_loss = F.binary_cross_entropy_with_logits(pos_score, torch.ones_like(pos_score), reduction='sum')\n",
        "                neg_loss = F.binary_cross_entropy_with_logits(neg_scores, torch.zeros_like(neg_scores), reduction='sum')\n",
        "\n",
        "                # Step 2: Sample synonym pairs and compute synonym loss\n",
        "                # Sample m synonym pairs with replacement\n",
        "                sampled_pairs = random.choices(synonym_pairs, k=m)\n",
        "                w1_indices = torch.tensor([pair[0] for pair in sampled_pairs], device=device)\n",
        "                w2_indices = torch.tensor([pair[1] for pair in sampled_pairs], device=device)\n",
        "\n",
        "                # Get embeddings for synonym pairs\n",
        "                target_emb_w1 = model.target_embeddings(w1_indices)\n",
        "                context_emb_w2 = model.context_embeddings(w2_indices)\n",
        "                syn_score = (target_emb_w1 * context_emb_w2).sum(dim=1)\n",
        "\n",
        "                # Synonym loss to encourage similarity\n",
        "                syn_loss = F.binary_cross_entropy_with_logits(syn_score, torch.ones_like(syn_score), reduction='sum')\n",
        "\n",
        "                # Step 3: Combine losses\n",
        "                loss = (pos_loss + neg_loss + lambdda * syn_loss) / targets.size(0)\n",
        "\n",
        "                # Backpropagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                pbar.set_postfix({'loss': loss.item()})\n",
        "\n",
        "        print(f'Epoch {epoch+1}, Average Loss: {total_loss / len(dataloader)}')\n",
        "\n",
        "    save_path = os.path.join(save_dir, model_name)\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "    print(f'Model weights saved to {save_path}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6kXt3HuuchIB"
      },
      "source": [
        "##### Let's check if it works"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ov2BXxynbivZ"
      },
      "outputs": [],
      "source": [
        "model_100_knowledge = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSxb4u1Tco5R",
        "outputId": "b41d4ae6-a3ed-4e71-d690-1350c2f15b39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 65240 synonym pairs from WordNet.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 11180/11180 [02:07<00:00, 87.83batch/s, loss=2.31] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 3.7862475979946595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 11180/11180 [02:04<00:00, 89.52batch/s, loss=2.25] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 2.188947153709869\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 11180/11180 [02:07<00:00, 87.80batch/s, loss=2.13] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 2.125254548918156\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 11180/11180 [02:04<00:00, 89.89batch/s, loss=2.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 2.10561693280882\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.59batch/s, loss=2.07]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 2.097024903378461\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 11180/11180 [02:04<00:00, 89.57batch/s, loss=2.09]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 2.0919627403317285\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.71batch/s, loss=2.15]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 2.0891373323626508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 11180/11180 [02:05<00:00, 89.06batch/s, loss=2.1] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 2.087162859441982\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 11180/11180 [02:06<00:00, 88.52batch/s, loss=2.24] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 2.08559569080955\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 11180/11180 [02:03<00:00, 90.52batch/s, loss=2.16]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 2.0844823240487433\n",
            "Model weights saved to model_checkpoints/100_knowledge.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model_knowledge(model_100_knowledge, '100_knowledge.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxEnTJ8L6KE2"
      },
      "source": [
        "**Let's try to make the new loss way more important and see what it will result at**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "uXJRjBOt6app"
      },
      "outputs": [],
      "source": [
        "model_100_knowledge_importance = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p1evtfJw6Ivv",
        "outputId": "904cf6ec-2cd5-4f02-c420-7c57c7606c86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 65240 synonym pairs from WordNet.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1/10: 100%|██████████| 11180/11180 [02:09<00:00, 86.53batch/s, loss=2.37]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Average Loss: 3.950470957026712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2/10: 100%|██████████| 11180/11180 [02:09<00:00, 86.37batch/s, loss=2.15] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2, Average Loss: 2.235824123456781\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3/10: 100%|██████████| 11180/11180 [02:08<00:00, 86.96batch/s, loss=2.23]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3, Average Loss: 2.1639981471788476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4/10: 100%|██████████| 11180/11180 [02:09<00:00, 86.45batch/s, loss=2.17]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4, Average Loss: 2.1425531519333663\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5/10: 100%|██████████| 11180/11180 [02:10<00:00, 85.69batch/s, loss=2.13]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5, Average Loss: 2.1331264216272903\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6/10: 100%|██████████| 11180/11180 [02:07<00:00, 87.79batch/s, loss=2.12]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6, Average Loss: 2.127753461814737\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7/10: 100%|██████████| 11180/11180 [02:11<00:00, 85.08batch/s, loss=2.17] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7, Average Loss: 2.124710267281063\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8/10: 100%|██████████| 11180/11180 [02:07<00:00, 87.35batch/s, loss=2.2]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8, Average Loss: 2.1228138141320727\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9/10: 100%|██████████| 11180/11180 [02:11<00:00, 85.27batch/s, loss=2.18]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9, Average Loss: 2.121129121059595\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10/10: 100%|██████████| 11180/11180 [02:08<00:00, 86.93batch/s, loss=2.17]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10, Average Loss: 2.1202801537321805\n",
            "Model weights saved to model_checkpoints/100_knowledge_importance.pt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_model_knowledge(model_100_knowledge_importance, '100_knowledge_importance.pt', lambdda=2, m=512)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuNtYi5hco7e",
        "outputId": "888d2eff-4e2a-4986-cf83-223ad6b2bfd8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.4615\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.4615047166264469"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# metric we need to beat: 0.4319\n",
        "checkpoint = torch.load('model_checkpoints/100_knowledge.pt', map_location=device)\n",
        "model_100_knowledge = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)\n",
        "model_100_knowledge.load_state_dict(checkpoint)\n",
        "compute_correlation(model_100_knowledge, wordsim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGUeD8Xz8OUz",
        "outputId": "f61eddbf-32a7-48a2-9114-371adf2b80d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.4935\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.49346005577594065"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# metric we need to beat: 0.4319\n",
        "checkpoint = torch.load('model_checkpoints/100_knowledge_importance.pt', map_location=device)\n",
        "model_100_knowledge_importance = SkipGramModel(vocab_size=len(dataset.word_to_index), embedding_dim=100).to(device)\n",
        "model_100_knowledge_importance.load_state_dict(checkpoint)\n",
        "compute_correlation(model_100_knowledge_importance, wordsim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCZcJNA6forJ"
      },
      "source": [
        "**Okay, in this case the metric improved. Hence, probably the proposed improvements make sense. The model with more influence of the external knowledge performs better than the one having less influence of the external knowledge. However, this single metric is not that straightforward, and I do not think we can compare the model performances based on it only. Fortunately, we have other metrics. For example, it is worth trying to visualize the embeddings (not all, a small part since there are too many words in the vocabulary), and to see the most similar words to a particular word. Let's do it**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "lUWyMxkCco_N"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "    <style>\n",
              "        .bk-notebook-logo {\n",
              "            display: block;\n",
              "            width: 20px;\n",
              "            height: 20px;\n",
              "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
              "        }\n",
              "    </style>\n",
              "    <div>\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
              "        <span id=\"d3dd3e4e-f6d2-4876-83dc-decdb6ce9761\">Loading BokehJS ...</span>\n",
              "    </div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"d3dd3e4e-f6d2-4876-83dc-decdb6ce9761\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"d3dd3e4e-f6d2-4876-83dc-decdb6ce9761\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from quality_assessment import most_similar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Check the results with most similar words\n",
        "\n",
        "**We will compare three models:**\n",
        "\n",
        "+ emb_dim_100 - the first Word2Vec we trained (no knowledge, embedding size=100)\n",
        "\n",
        "+ 100_knowledge - we use knowledge (WordNet dataset), but the weight of it is very low\n",
        "\n",
        "+ 100_knowledge_importance - loss defined by using WordNet dataset is used and it is very important\n",
        "\n",
        "**The goal is to figute out, whether the modification we introduced in this section makes sense.** Keep in mind that I will use subjective rules to identify it (check the most similar words, visualize the embeddings). However, I will try to truly estimate, whether the experience made sense or no"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Apple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNGpgwHRXK7f",
        "outputId": "9ae7ed7f-91dc-414c-a740-14fd963ceb8b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['ios', 'android', 'microsoft', 'amazon', 'lemon']"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# makes sense; maybe not the type of apple that we want, but keep in mind that we are using random wikipeida articles for training\n",
        "# the best out of three\n",
        "most_similar('emb_dim_100.pt', 'apple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0dLNVqlBhrF",
        "outputId": "a22756c7-eb4a-4770-ae97-dc40fce9294d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['inc', 'hardware', 'coffee', 'keynote', 'electronics']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# worse\n",
        "most_similar('100_knowledge.pt', 'apple')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmP3EISxBnyE",
        "outputId": "86c8e76d-5157-4141-88a6-4f6dda3e231c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['coconut', 'sugar', 'manufacturing', 'egg', 'nut']"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# worse\n",
        "most_similar('100_knowledge_importance.pt', 'apple')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lemon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yY2IrjC65D9Q",
        "outputId": "6fdf510b-282f-4fac-f16c-dcac92c2c2aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['lime', 'mango', 'sticks', 'citrus', 'mouse']"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# not bad\n",
        "most_similar('emb_dim_100.pt', 'lemon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cD9mMAT8BwNg",
        "outputId": "a5bb6adc-c690-4e65-c319-b6d1098ac17d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['leaf', 'citron', 'lime', 'mandarins', 'grapefruit']"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better, this and the next one are the best\n",
        "most_similar('100_knowledge.pt', 'lemon')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9ejEYKPBwQ0",
        "outputId": "5fdee131-322b-4aa7-bf3c-3aa4901bbe7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['papilio', 'grapefruit', 'orange', 'oranges', 'citron']"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# better, this and the previous one are the best\n",
        "most_similar('100_knowledge_importance.pt', 'lemon')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "University"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAnDEgw15Wx6",
        "outputId": "18b36d5b-3847-4287-d3cb-b050a52441b5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['faculty', 'college', 'institute', 'polytechnic', 'stanford']"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# good, all three are good\n",
        "most_similar('emb_dim_100.pt', 'university')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZyE2TmBdB2uj",
        "outputId": "9e9dfa81-d372-44d7-816c-fe63bb3f7a1d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['college', 'institute', 'harvard', 'museum', 'faculty']"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# good, all three are good\n",
        "most_similar('100_knowledge.pt', 'university')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkZfLDfoB2ws",
        "outputId": "38548fe6-9bea-451c-a34d-94dc0bb246a0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['college', 'stanford', 'polytechnic', 'faculty', 'campus']"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# good, all three are good\n",
        "most_similar('100_knowledge_importance.pt', 'university')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Human"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MreHZYhTB2y0",
        "outputId": "68ea18ea-6b78-4bb5-8d88-0264f472af44"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['rights', 'social', 'cells', 'animal', 'violence']"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "most_similar('emb_dim_100.pt', 'human')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORtlKgrw53dY",
        "outputId": "e4ecadfc-577e-46b1-c7d2-69d54226bf5d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['prevention', 'rights', 'genetic', 'animal', 'related']"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "most_similar('100_knowledge.pt', 'human')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAehCU7Z5ngp",
        "outputId": "e2ddfc1b-97b6-473c-e0ad-787cb34f9154"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['humans', 'environmental', 'humanity', 'economic', 'behavioral']"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# I think this makes the most sense, but others are good as well\n",
        "most_similar('100_knowledge_importance.pt', 'human')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Bottle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wsQZjaLoCB7o",
        "outputId": "1515b786-8762-4e06-aac8-343a3b6bc268"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['wine', 'thread', 'slice', 'set', 'cloth']"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# makes the least sense\n",
        "most_similar('emb_dim_100.pt', 'bottle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alAOv3LBCB99",
        "outputId": "7a0dafbe-5a15-4a53-96c6-61f8f2068292"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['sheet', 'tree', 'plastic', 'sheets', 'bones']"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "most_similar('100_knowledge.pt', 'bottle')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qL59OPikCCAM",
        "outputId": "02d406c1-a846-407c-f4b4-aef87015043b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-45-d6f2ccda71dc>:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_path, map_location=device)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['wine', 'beats', 'bath', 'bottles', 'glass']"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# makes the most sense\n",
        "most_similar('100_knowledge_importance.pt', 'bottle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check some synonym pairs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "later after\n",
            "after later\n",
            "withdraw retreat\n",
            "retreat withdraw\n",
            "withdraw retire\n",
            "retire withdraw\n",
            "withdraw recall\n",
            "recall withdraw\n",
            "withdraw draw\n",
            "draw withdraw\n",
            "withdraw remove\n",
            "remove withdraw\n",
            "withdraw take\n",
            "take withdraw\n",
            "home place\n"
          ]
        }
      ],
      "source": [
        "for pair in synonym_pairs[140:155]:\n",
        "    print(dataset.convert_idx_to_word(pair[0]), dataset.convert_idx_to_word(pair[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "arena area\n",
            "area arena\n",
            "arena orbit\n",
            "orbit arena\n",
            "arena field\n",
            "field arena\n",
            "arena stadium\n",
            "stadium arena\n",
            "arena bowl\n",
            "bowl arena\n"
          ]
        }
      ],
      "source": [
        "for pair in synonym_pairs[180:190]:\n",
        "    print(dataset.convert_idx_to_word(pair[0]), dataset.convert_idx_to_word(pair[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Based on this, let's check the following words: withdraw, arena\n",
        "\n",
        "Based on these examples, we are expected to see the following words: \n",
        "\n",
        "withdraw -> remove, take, retreat, retire, recall\n",
        "\n",
        "arena -> orbit, field, bowl, stadium"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['immediately', 'proceeded', 'illegally', 'resign', 'arrest']"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0 intersections with out expectations\n",
        "most_similar('emb_dim_100.pt', 'withdraw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['remove', 'retire', 'call', 'convert', 'retreat']"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 3 intesections with our expectations\n",
        "most_similar('100_knowledge.pt', 'withdraw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['remove', 'withdrew', 'retreat', 'pull', 'retire']"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4 intersections with our expectations !!!\n",
        "most_similar('100_knowledge_importance.pt', 'withdraw')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['coliseum', 'center', 'steelhawks', 'saturday', 'edt']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 0 intersections with our expectations\n",
        "most_similar('emb_dim_100.pt', 'arena')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['coliseum', 'indoor', 'stadium', 'raiders', 'steelhawks']"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 1 intersection with our expectations\n",
        "most_similar('100_knowledge.pt', 'arena')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['stadium', 'arenas', 'field', 'lancers', 'coliseum']"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2 intersections with our expectations\n",
        "most_similar('100_knowledge_importance.pt', 'arena')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Draw conclusions based on the most similar words analysis:\n",
        "\n",
        "+ The new approach and the new loss function work! It is clearly seen that new Word2Vec model adjusts its embeddings to match the expectations of the WordNet dataset (see the last experiment to make sure)\n",
        "\n",
        "+ In terms of arbitrary words (not the ones we were specifically looking at using the WordNet dataset), I think the new Word2Vec model (with external knowledge), on average, makes a bit more sense, but just a little bit. Meanwhile, I have no questions regarding if the approach works \n",
        "\n",
        "+ Instead, the quality of the WordNet dataset is questionable. I do not think it is very useful in our task. Hence, we do not need to rely on it a lot, and limit the influence of this dataset (this can be easily done with the hyperparameters we introduced, m and lambda)\n",
        "\n",
        "+ Much more important thing is having more data and more time to train (at least much more Wiki articles, more training epochs, maybe some experiments with the architecture)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Let's visualize the embeddings**\n",
        "\n",
        "Inspired by: https://github.com/ashaba1in/hse-nlp/blob/main/2023/seminars/week1_word_embeddings.ipynb (NLP course from my undergrad)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "67Zcb6i4Dz62"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "    <style>\n",
              "        .bk-notebook-logo {\n",
              "            display: block;\n",
              "            width: 20px;\n",
              "            height: 20px;\n",
              "            background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAABx0RVh0U29mdHdhcmUAQWRvYmUgRmlyZXdvcmtzIENTNui8sowAAAOkSURBVDiNjZRtaJVlGMd/1/08zzln5zjP1LWcU9N0NkN8m2CYjpgQYQXqSs0I84OLIC0hkEKoPtiH3gmKoiJDU7QpLgoLjLIQCpEsNJ1vqUOdO7ppbuec5+V+rj4ctwzd8IIbbi6u+8f1539dt3A78eXC7QizUF7gyV1fD1Yqg4JWz84yffhm0qkFqBogB9rM8tZdtwVsPUhWhGcFJngGeWrPzHm5oaMmkfEg1usvLFyc8jLRqDOMru7AyC8saQr7GG7f5fvDeH7Ej8CM66nIF+8yngt6HWaKh7k49Soy9nXurCi1o3qUbS3zWfrYeQDTB/Qj6kX6Ybhw4B+bOYoLKCC9H3Nu/leUTZ1JdRWkkn2ldcCamzrcf47KKXdAJllSlxAOkRgyHsGC/zRday5Qld9DyoM4/q/rUoy/CXh3jzOu3bHUVZeU+DEn8FInkPBFlu3+nW3Nw0mk6vCDiWg8CeJaxEwuHS3+z5RgY+YBR6V1Z1nxSOfoaPa4LASWxxdNp+VWTk7+4vzaou8v8PN+xo+KY2xsw6une2frhw05CTYOmQvsEhjhWjn0bmXPjpE1+kplmmkP3suftwTubK9Vq22qKmrBhpY4jvd5afdRA3wGjFAgcnTK2s4hY0/GPNIb0nErGMCRxWOOX64Z8RAC4oCXdklmEvcL8o0BfkNK4lUg9HTl+oPlQxdNo3Mg4Nv175e/1LDGzZen30MEjRUtmXSfiTVu1kK8W4txyV6BMKlbgk3lMwYCiusNy9fVfvvwMxv8Ynl6vxoByANLTWplvuj/nF9m2+PDtt1eiHPBr1oIfhCChQMBw6Aw0UulqTKZdfVvfG7VcfIqLG9bcldL/+pdWTLxLUy8Qq38heUIjh4XlzZxzQm19lLFlr8vdQ97rjZVOLf8nclzckbcD4wxXMidpX30sFd37Fv/GtwwhzhxGVAprjbg0gCAEeIgwCZyTV2Z1REEW8O4py0wsjeloKoMr6iCY6dP92H6Vw/oTyICIthibxjm/DfN9lVz8IqtqKYLUXfoKVMVQVVJOElGjrnnUt9T9wbgp8AyYKaGlqingHZU/uG2NTZSVqwHQTWkx9hxjkpWDaCg6Ckj5qebgBVbT3V3NNXMSiWSDdGV3hrtzla7J+duwPOToIg42ChPQOQjspnSlp1V+Gjdged7+8UN5CRAV7a5EdFNwCjEaBR27b3W890TE7g24NAP/mMDXRWrGoFPQI9ls/MWO2dWFAar/xcOIImbbpA3zgAAAABJRU5ErkJggg==);\n",
              "        }\n",
              "    </style>\n",
              "    <div>\n",
              "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-notebook-logo\"></a>\n",
              "        <span id=\"de03c173-be26-43d4-a708-d67e3c6257c7\">Loading BokehJS ...</span>\n",
              "    </div>\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "'use strict';\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    function drop(id) {\n      const view = Bokeh.index.get_by_id(id)\n      if (view != null) {\n        view.model.document.clear()\n        Bokeh.index.delete(view)\n      }\n    }\n\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n\n    // Clean up Bokeh references\n    if (id != null) {\n      drop(id)\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim()\n            drop(id)\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded(error = null) {\n    const el = document.getElementById(\"de03c173-be26-43d4-a708-d67e3c6257c7\");\n    if (el != null) {\n      const html = (() => {\n        if (typeof root.Bokeh === \"undefined\") {\n          if (error == null) {\n            return \"BokehJS is loading ...\";\n          } else {\n            return \"BokehJS failed to load.\";\n          }\n        } else {\n          const prefix = `BokehJS ${root.Bokeh.version}`;\n          if (error == null) {\n            return `${prefix} successfully loaded.`;\n          } else {\n            return `${prefix} <b>encountered errors</b> while loading and may not function as expected.`;\n          }\n        }\n      })();\n      el.innerHTML = html;\n\n      if (error != null) {\n        const wrapper = document.createElement(\"div\");\n        wrapper.style.overflow = \"auto\";\n        wrapper.style.height = \"5em\";\n        wrapper.style.resize = \"vertical\";\n        const content = document.createElement(\"div\");\n        content.style.fontFamily = \"monospace\";\n        content.style.whiteSpace = \"pre-wrap\";\n        content.style.backgroundColor = \"rgb(255, 221, 221)\";\n        content.textContent = error.stack ?? error.toString();\n        wrapper.append(content);\n        el.append(wrapper);\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(() => display_loaded(error), 100);\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-3.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-3.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n      try {\n            for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n\n      } catch (error) {display_loaded(error);throw error;\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"de03c173-be26-43d4-a708-d67e3c6257c7\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
            "application/vnd.bokehjs_load.v0+json": ""
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import bokeh.models as bm\n",
        "import bokeh.plotting as pl\n",
        "from bokeh.io import output_notebook\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.manifold import TSNE\n",
        "from quality_assessment import visualize_embeddings_interactive\n",
        "\n",
        "# Ensure Bokeh output is set to notebook if using Jupyter\n",
        "output_notebook()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "jC4ov6wuD0RP",
        "outputId": "4701b43f-905c-42fc-98c2-546a9acafc10"
      },
      "outputs": [],
      "source": [
        "# model without the external knowledge\n",
        "# both this model and the next one are good and make sense. I will summarize the results of the next model in the cell below\n",
        "visualize_embeddings_interactive(model_name='emb_dim_100.pt', num_words=1000, seed=42, device=device,\n",
        "                                    radius=10, alpha=0.5, color='blue',\n",
        "                                    width=1000, height=800, show=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890
        },
        "id": "lZR7njO7Ffp7",
        "outputId": "df2e1f8d-57c4-407d-8077-eca10b70533c"
      },
      "outputs": [],
      "source": [
        "# model with the external knowledge\n",
        "visualize_embeddings_interactive(model_name='100_knowledge_importance.pt', num_words=1000, seed=42, device=device,\n",
        "                                    radius=10, alpha=0.5, color='blue',\n",
        "                                    width=1000, height=800, show=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwV0NvXzGItV"
      },
      "source": [
        "##### Analysis of the visual results\n",
        "\n",
        "**I will summarize what I saw at the knowledge model graph. However, most of these results are also applicable to a model without the external knowledge (but probably the model with the knowledge makes slightly more sense)**\n",
        "\n",
        "+ I see that the locations (like the US states), and the professions are close to each other. Also some unusual words (perhaps from the same languages which are not English) are close to each other\n",
        "\n",
        "+ Words in the past tense are close to each other (like brought, agreed, etc.)\n",
        "\n",
        "+ Some specific terminology (like bridge, resorvoir, mine, gate, which is probably related to some factory or constuction) are close to each other\n",
        "\n",
        "+ Countries are close to each other (Cuba, Iceland, Mongolia, Arabia, etc.) are close to each other but far from the states which I mentioned before\n",
        "\n",
        "+ Overall, it really makes sense at least in many cases, and obviously I did not summarize everything, these are just some examples. I think the model is good, especially given the data quality and quantity, and the resource contraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2 Pretrained Model Embedding Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "FsfhCV6PD0Th"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"openbmb/MiniCPM-1B-sft-bf16\", trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\"openbmb/MiniCPM-1B-sft-bf16\", trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**We will extract embeddings from the input embedding matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1536])\n",
            "torch.Size([2, 1536])\n",
            "torch.Size([1, 1536])\n",
            "torch.Size([1, 1536])\n",
            "torch.Size([2, 1536])\n"
          ]
        }
      ],
      "source": [
        "all_embeddings = model.get_input_embeddings()\n",
        "words = [\"apple\", \"appple\", \"chair\", \"boy\", \"peach\"]\n",
        "embedding_reflection = {}\n",
        "for word in words:\n",
        "    tokens = tokenizer.encode(word, add_special_tokens=False)\n",
        "    word_embeddings = []\n",
        "    for token in tokens:\n",
        "        word_embedding = all_embeddings(torch.tensor(token))\n",
        "        word_embeddings.append(word_embedding)\n",
        "    word_embeddings = torch.stack(word_embeddings)\n",
        "    print(word_embeddings.shape)\n",
        "    embedding_reflection[word] = word_embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "apple apple = 1.000000238418579\n",
            "apple appple = 0.6285947561264038\n",
            "apple chair = 0.6110920906066895\n",
            "apple boy = 0.6109570860862732\n",
            "apple peach = 0.6368356347084045\n",
            "appple apple = 0.6285947561264038\n",
            "appple appple = 1.0000003576278687\n",
            "appple chair = 0.5873134136199951\n",
            "appple boy = 0.5639569163322449\n",
            "appple peach = 0.6722849011421204\n",
            "chair apple = 0.6110920906066895\n",
            "chair appple = 0.5873134136199951\n",
            "chair chair = 1.0000001192092896\n",
            "chair boy = 0.5883687734603882\n",
            "chair peach = 0.5883920788764954\n",
            "boy apple = 0.6109570860862732\n",
            "boy appple = 0.5639569163322449\n",
            "boy chair = 0.5883687734603882\n",
            "boy boy = 1.000000238418579\n",
            "boy peach = 0.6021623611450195\n",
            "peach apple = 0.6368356347084045\n",
            "peach appple = 0.6722849011421204\n",
            "peach chair = 0.5883920788764954\n",
            "peach boy = 0.6021623611450195\n",
            "peach peach = 1.000000238418579\n"
          ]
        }
      ],
      "source": [
        "for word1, embedding1 in embedding_reflection.items():\n",
        "    for word2, embedding2 in embedding_reflection.items():\n",
        "\n",
        "        # here we simply use the average embeddings if one word are encoded into many tokens\n",
        "        avg_embedding1 = torch.mean(embedding1, dim=0, keepdim=True)\n",
        "        avg_embedding2 = torch.mean(embedding2, dim=0, keepdim=True)\n",
        "\n",
        "        cosine_sim = F.cosine_similarity(avg_embedding1, avg_embedding2)\n",
        "        print(f\"{word1} {word2} = {cosine_sim.item()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Seems like this is all I needed to do for this part of the assignment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3 Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Word Similarity Task:\n",
        "\n",
        "Use the WordSim353 dataset, which contains 353 word pairs with\n",
        "human-annotated similarity scores. Compute the Spearman’s rank cor-\n",
        "relation coefficient for the Word2Vec and Small Language Model embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In our case, wordsim was filtered (since words must occur in out vocabulary), and it has 304 word pairs in total. We calculated the Spearman’s rank correlation coefficient for each of the Word2Vec model just after we trained them (please refer to section 1.1 to see the details). In summary:\n",
        "\n",
        "Spearman’s correlation coefficient for the best model (embedding_dim=100) without the external knowledge: 0.4319\n",
        "\n",
        "Spearman’s correlation coefficient for the best model (embedding_dim=100) with the external knowledge: 0.3912\n",
        "\n",
        "Let's see how the model from huggingface will perform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word 1</th>\n",
              "      <th>Word 2</th>\n",
              "      <th>Human (Mean)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>admission</td>\n",
              "      <td>ticket</td>\n",
              "      <td>5.5360</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>alcohol</td>\n",
              "      <td>chemistry</td>\n",
              "      <td>4.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>aluminum</td>\n",
              "      <td>metal</td>\n",
              "      <td>6.6250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>announcement</td>\n",
              "      <td>effort</td>\n",
              "      <td>2.0625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>announcement</td>\n",
              "      <td>news</td>\n",
              "      <td>7.1875</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>weapon</td>\n",
              "      <td>secret</td>\n",
              "      <td>2.5000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>weather</td>\n",
              "      <td>forecast</td>\n",
              "      <td>5.4375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>wednesday</td>\n",
              "      <td>news</td>\n",
              "      <td>1.1250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>wood</td>\n",
              "      <td>forest</td>\n",
              "      <td>7.9375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>word</td>\n",
              "      <td>similarity</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>304 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Word 1      Word 2  Human (Mean)\n",
              "0       admission      ticket        5.5360\n",
              "1         alcohol   chemistry        4.1250\n",
              "2        aluminum       metal        6.6250\n",
              "3    announcement      effort        2.0625\n",
              "4    announcement        news        7.1875\n",
              "..            ...         ...           ...\n",
              "299        weapon      secret        2.5000\n",
              "300       weather    forecast        5.4375\n",
              "301     wednesday        news        1.1250\n",
              "302          wood      forest        7.9375\n",
              "303          word  similarity        0.8125\n",
              "\n",
              "[304 rows x 3 columns]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordsim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_embedding(word, tokenizer=tokenizer):\n",
        "    tokens = tokenizer.encode(word, add_special_tokens=False)\n",
        "    word_embeddings = []\n",
        "    for token in tokens:\n",
        "        word_embedding = all_embeddings(torch.tensor(token))\n",
        "        word_embeddings.append(word_embedding)\n",
        "    word_embeddings = torch.stack(word_embeddings)\n",
        "    word_embedding = torch.mean(word_embeddings, dim=0, keepdim=True)\n",
        "    return word_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1536])"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "apple_embedding = get_embedding('apple')\n",
        "apple_embedding.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_correlation(df):\n",
        "  cosine_similarities = []\n",
        "  human_scores = []\n",
        "  for index, row in df.iterrows():\n",
        "      word1 = row['Word 1']\n",
        "      word2 = row['Word 2']\n",
        "      human_score = row['Human (Mean)']\n",
        "\n",
        "      # Get embeddings for Word 1 and Word 2\n",
        "      embedding1 = get_embedding(word1)\n",
        "      embedding2 = get_embedding(word2)\n",
        "      # Compute cosine similarity\n",
        "      similarity = F.cosine_similarity(embedding1, embedding2).item()\n",
        "      cosine_similarities.append(similarity)\n",
        "      human_scores.append(human_score)\n",
        "\n",
        "  # Compute Spearman’s correlation coefficient\n",
        "  correlation, _ = spearmanr(cosine_similarities, human_scores)\n",
        "  print(f\"Spearman’s correlation coefficient: {correlation:.4f}\")\n",
        "  return correlation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spearman’s correlation coefficient: 0.6147\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6147075607558922"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Metric we need to beat: 0.4935\n",
        "compute_correlation(wordsim)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Analysis:\n",
        "\n",
        "Obviously, this model is better then the one we introduced in the section 1.2 (0.6147 vs 0.4935 in terms of correlation). It seems like the reasons are quite clear:\n",
        "\n",
        "+ Embedding dimension: 1536 vs 100\n",
        "\n",
        "+ More data (it is reasonable to assume the authors of the model we loaded used more data)\n",
        "\n",
        "+ More training epochs, more complex architecture, more time, and more resources\n",
        "\n",
        "+ Different model architecture (as Word2Vec was probably the first neural-based method). Obviously, architectures of such kind of models changed a lot (this one is probably a modified version of the transformer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Paraphrase Detection Task: In this task, you will use the embeddings\n",
        "\n",
        "Use either word or sentence embeddings to predict paraphrases. The task\n",
        "involves identifying whether a pair of sentences are paraphrases of each\n",
        "other. After obtaining the similarity score between the sentences, classify\n",
        "the pair as paraphrases if the score is greater than or equal to a predefined\n",
        "threshold (which should be fixed for the task), or as non-paraphrases if the\n",
        "score is below the threshold. Report the threshold and accuracy of each\n",
        "model on this task. Use the dataset msr paraphrase test.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Discuss the plan\n",
        "\n",
        "+ Even though the simple way is just to assign an arbitrary threshold for this task, it seems that it is better to do in a more smart way\n",
        "\n",
        "+ Since we have both the train set and the test set, we can identify the best of the candidates by maximizing the accuracy\n",
        "\n",
        "+ We will use the best out of out Skip-Gram models to set the threshold\n",
        "\n",
        "+ After that, we will have it fixed, and run both the Skip-Gram and the pre-trained LM on the test set\n",
        "\n",
        "+ We will look at the accuracy and at the confusion matrix\n",
        "\n",
        "+ This will be enough for the evaluation\n",
        "\n",
        "+ To convert Skip-Gram model to sentence embedding model, we will just take the average of word embeddings\n",
        "\n",
        "+ As for the pre-trained model, we already defined a get_embedding function, which will work\n",
        "\n",
        "\n",
        "I will use some code from here: https://www.kaggle.com/code/armandogru/va-a2 as a reference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "def clean_text(text):\n",
        "    text = str(text).lower().strip()\n",
        "    # Remove punctuation (you can adjust the regex if needed)\n",
        "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
        "    # Normalize whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>702876</td>\n",
              "      <td>702977</td>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2108705</td>\n",
              "      <td>2108831</td>\n",
              "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
              "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1330381</td>\n",
              "      <td>1330521</td>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3344667</td>\n",
              "      <td>3344648</td>\n",
              "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
              "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1236820</td>\n",
              "      <td>1236712</td>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>1</td>\n",
              "      <td>1620264</td>\n",
              "      <td>1620507</td>\n",
              "      <td>At this point, Mr. Brando announced: 'Somebody...</td>\n",
              "      <td>Brando said that \"somebody ought to put a bull...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>0</td>\n",
              "      <td>1848001</td>\n",
              "      <td>1848224</td>\n",
              "      <td>Martin, 58, will be freed today after serving ...</td>\n",
              "      <td>Martin served two thirds of a five-year senten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3914</th>\n",
              "      <td>1</td>\n",
              "      <td>747160</td>\n",
              "      <td>747144</td>\n",
              "      <td>We have concluded that the outlook for price s...</td>\n",
              "      <td>In a statement, the ECB said the outlook for p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3915</th>\n",
              "      <td>1</td>\n",
              "      <td>2539933</td>\n",
              "      <td>2539850</td>\n",
              "      <td>The notification was first reported Friday by ...</td>\n",
              "      <td>MSNBC.com first reported the CIA request on Fr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3916</th>\n",
              "      <td>0</td>\n",
              "      <td>453575</td>\n",
              "      <td>453448</td>\n",
              "      <td>The 30-year bond US30YT=RR rose 22/32 for a yi...</td>\n",
              "      <td>The 30-year bond US30YT=RR grew 1-3/32 for a y...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3917 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Quality    #1 ID    #2 ID  \\\n",
              "0           1   702876   702977   \n",
              "1           0  2108705  2108831   \n",
              "2           1  1330381  1330521   \n",
              "3           0  3344667  3344648   \n",
              "4           1  1236820  1236712   \n",
              "...       ...      ...      ...   \n",
              "3912        1  1620264  1620507   \n",
              "3913        0  1848001  1848224   \n",
              "3914        1   747160   747144   \n",
              "3915        1  2539933  2539850   \n",
              "3916        0   453575   453448   \n",
              "\n",
              "                                              #1 String  \\\n",
              "0     Amrozi accused his brother, whom he called \"th...   \n",
              "1     Yucaipa owned Dominick's before selling the ch...   \n",
              "2     They had published an advertisement on the Int...   \n",
              "3     Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
              "4     The stock rose $2.11, or about 11 percent, to ...   \n",
              "...                                                 ...   \n",
              "3912  At this point, Mr. Brando announced: 'Somebody...   \n",
              "3913  Martin, 58, will be freed today after serving ...   \n",
              "3914  We have concluded that the outlook for price s...   \n",
              "3915  The notification was first reported Friday by ...   \n",
              "3916  The 30-year bond US30YT=RR rose 22/32 for a yi...   \n",
              "\n",
              "                                              #2 String  \n",
              "0     Referring to him as only \"the witness\", Amrozi...  \n",
              "1     Yucaipa bought Dominick's in 1995 for $693 mil...  \n",
              "2     On June 10, the ship's owners had published an...  \n",
              "3     Tab shares jumped 20 cents, or 4.6%, to set a ...  \n",
              "4     PG&E Corp. shares jumped $1.63 or 8 percent to...  \n",
              "...                                                 ...  \n",
              "3912  Brando said that \"somebody ought to put a bull...  \n",
              "3913  Martin served two thirds of a five-year senten...  \n",
              "3914  In a statement, the ECB said the outlook for p...  \n",
              "3915  MSNBC.com first reported the CIA request on Fr...  \n",
              "3916  The 30-year bond US30YT=RR grew 1-3/32 for a y...  \n",
              "\n",
              "[3917 rows x 5 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paraphrase_train = pd.read_csv('msr_paraphrase_train.txt', sep='\\t', header=0, on_bad_lines='skip')\n",
        "paraphrase_train = paraphrase_train.loc[paraphrase_train['#1 String'].notna() & paraphrase_train['#2 String'].notna()]\n",
        "paraphrase_train.index = np.arange(0, len(paraphrase_train))\n",
        "paraphrase_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    2646\n",
              "0    1271\n",
              "Name: Quality, dtype: int64"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paraphrase_train.Quality.value_counts() # so there are actually more paraphrases than non-paraphrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1089874</td>\n",
              "      <td>1089925</td>\n",
              "      <td>PCCW's chief operating officer, Mike Butcher, ...</td>\n",
              "      <td>Current Chief Operating Officer Mike Butcher a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3019446</td>\n",
              "      <td>3019327</td>\n",
              "      <td>The world's two largest automakers said their ...</td>\n",
              "      <td>Domestic sales at both GM and No. 2 Ford Motor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1945605</td>\n",
              "      <td>1945824</td>\n",
              "      <td>According to the federal Centers for Disease C...</td>\n",
              "      <td>The Centers for Disease Control and Prevention...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1430402</td>\n",
              "      <td>1430329</td>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "      <td>A tropical storm rapidly developed in the Gulf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>3354381</td>\n",
              "      <td>3354396</td>\n",
              "      <td>The company didn't detail the costs of the rep...</td>\n",
              "      <td>But company officials expect the costs of the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1625</th>\n",
              "      <td>0</td>\n",
              "      <td>2685984</td>\n",
              "      <td>2686122</td>\n",
              "      <td>After Hughes refused to rehire Hernandez, he c...</td>\n",
              "      <td>Hernandez filed an Equal Employment Opportunit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1626</th>\n",
              "      <td>0</td>\n",
              "      <td>339215</td>\n",
              "      <td>339172</td>\n",
              "      <td>There are 103 Democrats in the Assembly and 47...</td>\n",
              "      <td>Democrats dominate the Assembly while Republic...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1627</th>\n",
              "      <td>0</td>\n",
              "      <td>2996850</td>\n",
              "      <td>2996734</td>\n",
              "      <td>Bethany Hamilton remained in stable condition ...</td>\n",
              "      <td>Bethany, who remained in stable condition afte...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1628</th>\n",
              "      <td>1</td>\n",
              "      <td>2095781</td>\n",
              "      <td>2095812</td>\n",
              "      <td>Last week the power station’s US owners, AES C...</td>\n",
              "      <td>The news comes after Drax's American owner, AE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1629</th>\n",
              "      <td>1</td>\n",
              "      <td>2136244</td>\n",
              "      <td>2136052</td>\n",
              "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
              "      <td>The virus spreads when unsuspecting computer u...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1630 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Quality    #1 ID    #2 ID  \\\n",
              "0           1  1089874  1089925   \n",
              "1           1  3019446  3019327   \n",
              "2           1  1945605  1945824   \n",
              "3           0  1430402  1430329   \n",
              "4           0  3354381  3354396   \n",
              "...       ...      ...      ...   \n",
              "1625        0  2685984  2686122   \n",
              "1626        0   339215   339172   \n",
              "1627        0  2996850  2996734   \n",
              "1628        1  2095781  2095812   \n",
              "1629        1  2136244  2136052   \n",
              "\n",
              "                                              #1 String  \\\n",
              "0     PCCW's chief operating officer, Mike Butcher, ...   \n",
              "1     The world's two largest automakers said their ...   \n",
              "2     According to the federal Centers for Disease C...   \n",
              "3     A tropical storm rapidly developed in the Gulf...   \n",
              "4     The company didn't detail the costs of the rep...   \n",
              "...                                                 ...   \n",
              "1625  After Hughes refused to rehire Hernandez, he c...   \n",
              "1626  There are 103 Democrats in the Assembly and 47...   \n",
              "1627  Bethany Hamilton remained in stable condition ...   \n",
              "1628  Last week the power station’s US owners, AES C...   \n",
              "1629  Sobig.F spreads when unsuspecting computer use...   \n",
              "\n",
              "                                              #2 String  \n",
              "0     Current Chief Operating Officer Mike Butcher a...  \n",
              "1     Domestic sales at both GM and No. 2 Ford Motor...  \n",
              "2     The Centers for Disease Control and Prevention...  \n",
              "3     A tropical storm rapidly developed in the Gulf...  \n",
              "4     But company officials expect the costs of the ...  \n",
              "...                                                 ...  \n",
              "1625  Hernandez filed an Equal Employment Opportunit...  \n",
              "1626  Democrats dominate the Assembly while Republic...  \n",
              "1627  Bethany, who remained in stable condition afte...  \n",
              "1628  The news comes after Drax's American owner, AE...  \n",
              "1629  The virus spreads when unsuspecting computer u...  \n",
              "\n",
              "[1630 rows x 5 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "paraphrase_test = pd.read_csv('msr_paraphrase_test.txt', sep='\\t', header=0, on_bad_lines='skip')\n",
        "paraphrase_test = paraphrase_test.loc[paraphrase_test['#1 String'].notna() & paraphrase_test['#2 String'].notna()]\n",
        "paraphrase_test.index = np.arange(0, len(paraphrase_test))\n",
        "paraphrase_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "paraphrase_train['#1 String'] = paraphrase_train['#1 String'].apply(clean_text)\n",
        "paraphrase_train['#2 String'] = paraphrase_train['#2 String'].apply(lambda x: clean_text(x) if pd.notna(x) else \"\")\n",
        "\n",
        "paraphrase_test['#1 String'] = paraphrase_test['#1 String'].apply(clean_text)\n",
        "paraphrase_test['#2 String'] = paraphrase_test['#2 String'].apply(lambda x: clean_text(x) if pd.notna(x) else \"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = os.path.join('model_checkpoints', '100_knowledge_importance.pt')\n",
        "checkpoint = torch.load(save_path, map_location=device)\n",
        "vocab_size = len(vocab)\n",
        "idx_to_word = dataset.convert_idx_to_word\n",
        "word_to_idx = dataset.convert_word_to_idx\n",
        "model_100_knowledge_importance = SkipGramModel(vocab_size, embedding_dim=100).to(device)\n",
        "model_100_knowledge_importance.load_state_dict(checkpoint)\n",
        "model_100_knowledge_importance.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [],
      "source": [
        "def convert_sentence_to_embedding(sentence, model=model_100_knowledge_importance):\n",
        "    lst_sentence = sentence.split()\n",
        "    lst_sentence = [word_to_idx(word) for word in lst_sentence if word in vocab]\n",
        "    embeddings = model.target_embeddings.weight\n",
        "    sampled_embeddings = embeddings[lst_sentence].cpu().detach().numpy()\n",
        "    sentence_embedding = np.mean(sampled_embeddings, axis=0)\n",
        "    return sentence_embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "def similar_or_not(df, threshold, pretrained_model=False):\n",
        "  df['Model_answer'] = -1\n",
        "  df['Similarity'] = -1\n",
        "  for index, row in df.iterrows():\n",
        "      sentence1 = row['#1 String']\n",
        "      sentence2 = row['#2 String']\n",
        "      answer = row['Quality']\n",
        "      if pretrained_model:\n",
        "         embedding1 = get_embedding(sentence1, tokenizer=tokenizer)\n",
        "         embedding2 = get_embedding(sentence2, tokenizer=tokenizer)\n",
        "         similarity = F.cosine_similarity(embedding1, embedding2).item()\n",
        "      else:\n",
        "          embedding1 = convert_sentence_to_embedding(sentence1)\n",
        "          embedding2 = convert_sentence_to_embedding(sentence2)\n",
        "          similarity = cosine_similarity([embedding1], [embedding2])[0][0]  # Convert to Python float\n",
        "      df.at[index, 'Similarity'] = similarity\n",
        "      if similarity >= threshold:\n",
        "          df.at[index, 'Model_answer'] = 1\n",
        "      else:\n",
        "          df.at[index, 'Model_answer'] = 0\n",
        "  return df, accuracy_score(df['Quality'], df['Model_answer'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.3\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.4\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.5\n",
            "Accuracy: 0.6757722747000255\n",
            "Threshold: 0.6\n",
            "Accuracy: 0.6783252489149859\n",
            "Threshold: 0.7\n",
            "Accuracy: 0.6880265509318356\n",
            "Threshold: 0.8\n",
            "Accuracy: 0.7018126116926219\n",
            "Threshold: 0.9\n",
            "Accuracy: 0.6622415113607353\n"
          ]
        }
      ],
      "source": [
        "# the best turned out to be 0.8\n",
        "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "accuracies = []\n",
        "for threshold in thresholds:\n",
        "    print(f\"Threshold: {threshold}\")\n",
        "    _, acc_train = similar_or_not(paraphrase_train, threshold)\n",
        "    print('Accuracy:', acc_train)\n",
        "    accuracies.append(acc_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that with threshold 0.3 and 0.4 the accuracy is the same, which is weird. The hypothesis is that there is no similarity which is less than 0.4. Let's check the hypothesis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "      <th>Model_answer</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>702876</td>\n",
              "      <td>702977</td>\n",
              "      <td>amrozi accused his brother whom he called the ...</td>\n",
              "      <td>referring to him as only the witness amrozi ac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.951396</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2108705</td>\n",
              "      <td>2108831</td>\n",
              "      <td>yucaipa owned dominicks before selling the cha...</td>\n",
              "      <td>yucaipa bought dominicks in 1995 for 693 milli...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.840388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1330381</td>\n",
              "      <td>1330521</td>\n",
              "      <td>they had published an advertisement on the int...</td>\n",
              "      <td>on june 10 the ships owners had published an a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.926847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3344667</td>\n",
              "      <td>3344648</td>\n",
              "      <td>around 0335 gmt tab shares were up 19 cents or...</td>\n",
              "      <td>tab shares jumped 20 cents or 46 to set a reco...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.886066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1236820</td>\n",
              "      <td>1236712</td>\n",
              "      <td>the stock rose 211 or about 11 percent to clos...</td>\n",
              "      <td>pge corp shares jumped 163 or 8 percent to 210...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.849477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>1</td>\n",
              "      <td>1620264</td>\n",
              "      <td>1620507</td>\n",
              "      <td>at this point mr brando announced somebody oug...</td>\n",
              "      <td>brando said that somebody ought to put a bulle...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.910437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>0</td>\n",
              "      <td>1848001</td>\n",
              "      <td>1848224</td>\n",
              "      <td>martin 58 will be freed today after serving tw...</td>\n",
              "      <td>martin served two thirds of a fiveyear sentenc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.899965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3914</th>\n",
              "      <td>1</td>\n",
              "      <td>747160</td>\n",
              "      <td>747144</td>\n",
              "      <td>we have concluded that the outlook for price s...</td>\n",
              "      <td>in a statement the ecb said the outlook for pr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.964827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3915</th>\n",
              "      <td>1</td>\n",
              "      <td>2539933</td>\n",
              "      <td>2539850</td>\n",
              "      <td>the notification was first reported friday by ...</td>\n",
              "      <td>msnbccom first reported the cia request on friday</td>\n",
              "      <td>0</td>\n",
              "      <td>0.799303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3916</th>\n",
              "      <td>0</td>\n",
              "      <td>453575</td>\n",
              "      <td>453448</td>\n",
              "      <td>the 30year bond us30ytrr rose 2232 for a yield...</td>\n",
              "      <td>the 30year bond us30ytrr grew 1332 for a yield...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.887820</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3917 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Quality    #1 ID    #2 ID  \\\n",
              "0           1   702876   702977   \n",
              "1           0  2108705  2108831   \n",
              "2           1  1330381  1330521   \n",
              "3           0  3344667  3344648   \n",
              "4           1  1236820  1236712   \n",
              "...       ...      ...      ...   \n",
              "3912        1  1620264  1620507   \n",
              "3913        0  1848001  1848224   \n",
              "3914        1   747160   747144   \n",
              "3915        1  2539933  2539850   \n",
              "3916        0   453575   453448   \n",
              "\n",
              "                                              #1 String  \\\n",
              "0     amrozi accused his brother whom he called the ...   \n",
              "1     yucaipa owned dominicks before selling the cha...   \n",
              "2     they had published an advertisement on the int...   \n",
              "3     around 0335 gmt tab shares were up 19 cents or...   \n",
              "4     the stock rose 211 or about 11 percent to clos...   \n",
              "...                                                 ...   \n",
              "3912  at this point mr brando announced somebody oug...   \n",
              "3913  martin 58 will be freed today after serving tw...   \n",
              "3914  we have concluded that the outlook for price s...   \n",
              "3915  the notification was first reported friday by ...   \n",
              "3916  the 30year bond us30ytrr rose 2232 for a yield...   \n",
              "\n",
              "                                              #2 String  Model_answer  \\\n",
              "0     referring to him as only the witness amrozi ac...             1   \n",
              "1     yucaipa bought dominicks in 1995 for 693 milli...             1   \n",
              "2     on june 10 the ships owners had published an a...             1   \n",
              "3     tab shares jumped 20 cents or 46 to set a reco...             1   \n",
              "4     pge corp shares jumped 163 or 8 percent to 210...             1   \n",
              "...                                                 ...           ...   \n",
              "3912  brando said that somebody ought to put a bulle...             1   \n",
              "3913  martin served two thirds of a fiveyear sentenc...             1   \n",
              "3914  in a statement the ecb said the outlook for pr...             1   \n",
              "3915  msnbccom first reported the cia request on friday             0   \n",
              "3916  the 30year bond us30ytrr grew 1332 for a yield...             1   \n",
              "\n",
              "      Similarity  \n",
              "0       0.951396  \n",
              "1       0.840388  \n",
              "2       0.926847  \n",
              "3       0.886066  \n",
              "4       0.849477  \n",
              "...          ...  \n",
              "3912    0.910437  \n",
              "3913    0.899965  \n",
              "3914    0.964827  \n",
              "3915    0.799303  \n",
              "3916    0.887820  \n",
              "\n",
              "[3917 rows x 7 columns]"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_analysis, acc_train = similar_or_not(paraphrase_train, 0.8)\n",
        "df_analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "      <th>Model_answer</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Quality, #1 ID, #2 ID, #1 String, #2 String, Model_answer, Similarity]\n",
              "Index: []"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Indeed, none of the points\n",
        "df_analysis.loc[df_analysis['Similarity'] <= 0.4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Time to compare the results between two models\n",
        "\n",
        "**Set threshold to be 0.8 for both models, which might not be a very good idea, since we took an optimal threshold according to the model we trained. Yet, this is what the task asks to do**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (Skip-Gram): 0.7049079754601227\n"
          ]
        }
      ],
      "source": [
        "df_test_our_model, acc_test_our_model = similar_or_not(paraphrase_test, 0.8)\n",
        "print('Accuracy (Skip-Gram):', acc_test_our_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy (Skip-Gram): 0.6638036809815951\n"
          ]
        }
      ],
      "source": [
        "df_test_pretained_model, acc_test_pretained_model = similar_or_not(paraphrase_test, 0.8, pretrained_model=True)\n",
        "print('Accuracy (Skip-Gram):', acc_test_pretained_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**For threshold=0.8, our model is slightly better than the pre_trained one (which basically assigned 1 to every observation). However, let's see the best possible behavior of the pre_trained model. The metrics for our model and the pre-trained model are 0.705 and 0.664, respectively.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Threshold: 0.3\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.4\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.5\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.6\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.7\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.8\n",
            "Accuracy: 0.6755169772785294\n",
            "Threshold: 0.9\n",
            "Accuracy: 0.6757722747000255\n"
          ]
        }
      ],
      "source": [
        "# check for the pre-trained model\n",
        "# the best turned out to be 0.8\n",
        "thresholds = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "accuracies = []\n",
        "for threshold in thresholds:\n",
        "    print(f\"Threshold: {threshold}\")\n",
        "    _, acc_train = similar_or_not(paraphrase_train, threshold, pretrained_model=True)\n",
        "    print('Accuracy:', acc_train)\n",
        "    accuracies.append(acc_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This looks very weird, because seems like all the similarities are very high. Let's check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "      <th>Model_answer</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>702876</td>\n",
              "      <td>702977</td>\n",
              "      <td>amrozi accused his brother whom he called the ...</td>\n",
              "      <td>referring to him as only the witness amrozi ac...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.993158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>2108705</td>\n",
              "      <td>2108831</td>\n",
              "      <td>yucaipa owned dominicks before selling the cha...</td>\n",
              "      <td>yucaipa bought dominicks in 1995 for 693 milli...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.989980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1330381</td>\n",
              "      <td>1330521</td>\n",
              "      <td>they had published an advertisement on the int...</td>\n",
              "      <td>on june 10 the ships owners had published an a...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.993228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>3344667</td>\n",
              "      <td>3344648</td>\n",
              "      <td>around 0335 gmt tab shares were up 19 cents or...</td>\n",
              "      <td>tab shares jumped 20 cents or 46 to set a reco...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.991016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1236820</td>\n",
              "      <td>1236712</td>\n",
              "      <td>the stock rose 211 or about 11 percent to clos...</td>\n",
              "      <td>pge corp shares jumped 163 or 8 percent to 210...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.986909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>1</td>\n",
              "      <td>1620264</td>\n",
              "      <td>1620507</td>\n",
              "      <td>at this point mr brando announced somebody oug...</td>\n",
              "      <td>brando said that somebody ought to put a bulle...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.989343</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>0</td>\n",
              "      <td>1848001</td>\n",
              "      <td>1848224</td>\n",
              "      <td>martin 58 will be freed today after serving tw...</td>\n",
              "      <td>martin served two thirds of a fiveyear sentenc...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.985217</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3914</th>\n",
              "      <td>1</td>\n",
              "      <td>747160</td>\n",
              "      <td>747144</td>\n",
              "      <td>we have concluded that the outlook for price s...</td>\n",
              "      <td>in a statement the ecb said the outlook for pr...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.991138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3915</th>\n",
              "      <td>1</td>\n",
              "      <td>2539933</td>\n",
              "      <td>2539850</td>\n",
              "      <td>the notification was first reported friday by ...</td>\n",
              "      <td>msnbccom first reported the cia request on friday</td>\n",
              "      <td>1</td>\n",
              "      <td>0.980402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3916</th>\n",
              "      <td>0</td>\n",
              "      <td>453575</td>\n",
              "      <td>453448</td>\n",
              "      <td>the 30year bond us30ytrr rose 2232 for a yield...</td>\n",
              "      <td>the 30year bond us30ytrr grew 1332 for a yield...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.996307</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3917 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Quality    #1 ID    #2 ID  \\\n",
              "0           1   702876   702977   \n",
              "1           0  2108705  2108831   \n",
              "2           1  1330381  1330521   \n",
              "3           0  3344667  3344648   \n",
              "4           1  1236820  1236712   \n",
              "...       ...      ...      ...   \n",
              "3912        1  1620264  1620507   \n",
              "3913        0  1848001  1848224   \n",
              "3914        1   747160   747144   \n",
              "3915        1  2539933  2539850   \n",
              "3916        0   453575   453448   \n",
              "\n",
              "                                              #1 String  \\\n",
              "0     amrozi accused his brother whom he called the ...   \n",
              "1     yucaipa owned dominicks before selling the cha...   \n",
              "2     they had published an advertisement on the int...   \n",
              "3     around 0335 gmt tab shares were up 19 cents or...   \n",
              "4     the stock rose 211 or about 11 percent to clos...   \n",
              "...                                                 ...   \n",
              "3912  at this point mr brando announced somebody oug...   \n",
              "3913  martin 58 will be freed today after serving tw...   \n",
              "3914  we have concluded that the outlook for price s...   \n",
              "3915  the notification was first reported friday by ...   \n",
              "3916  the 30year bond us30ytrr rose 2232 for a yield...   \n",
              "\n",
              "                                              #2 String  Model_answer  \\\n",
              "0     referring to him as only the witness amrozi ac...             1   \n",
              "1     yucaipa bought dominicks in 1995 for 693 milli...             1   \n",
              "2     on june 10 the ships owners had published an a...             1   \n",
              "3     tab shares jumped 20 cents or 46 to set a reco...             1   \n",
              "4     pge corp shares jumped 163 or 8 percent to 210...             1   \n",
              "...                                                 ...           ...   \n",
              "3912  brando said that somebody ought to put a bulle...             1   \n",
              "3913  martin served two thirds of a fiveyear sentenc...             1   \n",
              "3914  in a statement the ecb said the outlook for pr...             1   \n",
              "3915  msnbccom first reported the cia request on friday             1   \n",
              "3916  the 30year bond us30ytrr grew 1332 for a yield...             1   \n",
              "\n",
              "      Similarity  \n",
              "0       0.993158  \n",
              "1       0.989980  \n",
              "2       0.993228  \n",
              "3       0.991016  \n",
              "4       0.986909  \n",
              "...          ...  \n",
              "3912    0.989343  \n",
              "3913    0.985217  \n",
              "3914    0.991138  \n",
              "3915    0.980402  \n",
              "3916    0.996307  \n",
              "\n",
              "[3917 rows x 7 columns]"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_analysis_pretrained, acc_train = similar_or_not(paraphrase_train, 0.8, pretrained_model=True)\n",
        "df_analysis_pretrained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Quality</th>\n",
              "      <th>#1 ID</th>\n",
              "      <th>#2 ID</th>\n",
              "      <th>#1 String</th>\n",
              "      <th>#2 String</th>\n",
              "      <th>Model_answer</th>\n",
              "      <th>Similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2532</th>\n",
              "      <td>0</td>\n",
              "      <td>2662158</td>\n",
              "      <td>2662046</td>\n",
              "      <td>the standard edition is 15000 per processor or...</td>\n",
              "      <td>the standard edition one is a single processor...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.891606</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Quality    #1 ID    #2 ID  \\\n",
              "2532        0  2662158  2662046   \n",
              "\n",
              "                                              #1 String  \\\n",
              "2532  the standard edition is 15000 per processor or...   \n",
              "\n",
              "                                              #2 String  Model_answer  \\\n",
              "2532  the standard edition one is a single processor...             1   \n",
              "\n",
              "      Similarity  \n",
              "2532    0.891606  "
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# indeed, all the similarities are very high\n",
        "df_analysis_pretrained.loc[df_analysis_pretrained['Similarity'] <= 0.9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Make sure we did not get any mistakes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Compare my get_embedding model with the results from the reference_assignment1 notebook (made by the TA)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.6286], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same\n",
        "F.cosine_similarity(get_embedding('apple'), get_embedding('appple'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.6111], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same\n",
        "F.cosine_similarity(get_embedding('apple'), get_embedding('chair'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Make sure what I will check now matches the results obtained at the dataframe**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9932], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same\n",
        "F.cosine_similarity(get_embedding(df_analysis_pretrained['#1 String'][0]), get_embedding(df_analysis_pretrained['#2 String'][0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9910], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 91,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# same\n",
        "F.cosine_similarity(get_embedding(df_analysis_pretrained['#1 String'][3]), get_embedding(df_analysis_pretrained['#2 String'][3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**And, the get_embedding function will return the embedding both for the single word and for the sentence, as it tokenizes the input using its own tokenizer. Hence, seems like there is no mistake in the code I provided, and, indeed, the model just makes all the sentences very close to each other. It is probably a limitation of the model, since it was probably not designed for such a usecase. Probably the better approach will be to split a sentence by words, convert each word to an embedding, and then take the average. However, we will not do this and make a conclusion that our model performed better than the pre-trained one on this particular task, as the pre-trained model made all sentences very close to each other in terms of cosine similarity. Moreover, the accuracy of our model was better (since the pre-trained model just assigned score 1 to every pair of sentences on the threshold=0.8)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([0.9026], grad_fn=<SumBackward1>)"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "F.cosine_similarity(get_embedding('I am doing an NLP assignment'), get_embedding('somebody once told me the world is gonna roll me'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4 Discussion and Analysis\n",
        "\n",
        "In this section, compare the performance of the Word2Vec embeddings with\n",
        "those generated by the small language model. Analyze the strengths and weaknesses of each approach. Discuss any challenges encountered during implementation and evaluation.\n",
        "\n",
        "**Basically, I've already written everything needed for this section as my comments while completing tasks in other sections. Hence, I will mention all the important details once again (but very briefly) here:**\n",
        "\n",
        "On the WordSim353 dataset, the small language model performed better than the best Skip-Gram model we trained (embedding_dimension=100, with significant influence of external knowledge obtained from the WordNet dataset). The results (Spearman correlation) are 0.6147 and 0.4935, respectively. We summarized the reasons as following:\n",
        "\n",
        "+ Embedding dimension: 1536 vs 100\n",
        "\n",
        "+ More data (it is reasonable to assume the authors of the model we loaded used more data)\n",
        "\n",
        "+ More training epochs, more complex architecture, more time, and more resources\n",
        "\n",
        "+ Different model architecture (as Word2Vec was probably the first neural-based method). Obviously, architectures of such kind of models changed a lot (this one is probably a modified version of the transformer)\n",
        "\n",
        "On the other hand, our Skip-Gram implementation performed better on another dataset - Paraphrase Detection Task. While both our model and the pre-trained one assign very high similarities (cosine similarity of the dot product of the embeddings) between the sentences, the pre-trained model makes them too high. That is why, given any adequate threshold, the predictions will be constant - according to the model, all the sentences will be the paraphrase of each other. Meanwhile, the Skip-Gram model will correctly predict some negative samples, making it a better model.\n",
        "\n",
        "We assumed there might be a mistake in code implementation in this task, resulting in very similar embeddings. However, after testing the hypothesis, it turned out that we didn't identify any code mistakes, and the model is really designed this way. Hence, the accuracies on the test set for the Skip-Gram model, and the pre-trained LLM, were approximately 0.705 and 0.664, respectively.\n",
        "\n",
        "##### Strengths of the custom Word2Vec implementation:\n",
        "\n",
        "**Domain-Specific customization**: Trained on a specific corpus, the embeddings reflect domain-specific semantics (e.g., medical, legal, or technical jargon). This is critical if the task involves specialized vocabulary or niche language patterns.\n",
        "\n",
        "**No dependency on external models and sources**: Full control over preprocessing, training data, and hyperparameters (e.g., window size, embedding dimensions).\n",
        "\n",
        "##### Weaknesses of the custom Word2Vec implementation:\n",
        "\n",
        "**Context insensitivity**: Assigns a single vector per word, ignoring context (e.g., \"bank\" as a financial institution vs. a riverbank). This limits performance on tasks requiring nuanced meaning.\n",
        "\n",
        "**Data, resource, and time requirements**: Requires a large, high-quality corpus to produce meaningful embeddings. Performance degrades with small or noisy datasets. Moreover, computational resources are needed in the ideal case, as Kaggle and Colab might not be enough to train a high-quality model.\n",
        "\n",
        "**Limited generalization**: Struggles with rare or out-of-vocabulary (OOV) words. Subword information is not captured (unlike models like FastText or other models that use different tokenizations or N-Gram approach).\n",
        "\n",
        "##### Strengths of using a pre-trained small LLM:\n",
        "\n",
        "**Contextual embeddings**: LLMs generate dynamic, context-aware vectors (e.g., \"bank\" in \"river bank\" vs. \"investment bank\" has distinct representations). This is critical for tasks like disambiguation, question answering, or sentiment analysis.\n",
        "\n",
        "**Transfer learning benefits**: Pre-trained models capture rich linguistic patterns (syntax, semantics, and even world knowledge) from vast datasets. Even smaller LLMs outperform Word2Vec on many NLP benchmarks.\n",
        "\n",
        "**Subword tokenization**: Handles OOV words via subword units (e.g., BERT’s WordPiece), improving generalization to rare or misspelled words.\n",
        "\n",
        "##### Weaknesses of the pre-trained small LLM:\n",
        "\n",
        "**Computational overhead**: Inference requires more resources (GPU/CPU and memory), especially for longer texts. Latency may be higher compared to Word2Vec.\n",
        "\n",
        "**Domain misalignment**: Pre-trained embeddings may not align with domain-specific terminology unless fine-tuned. For example, a general-purpose LLM might poorly represent technical terms in biomedicine.\n",
        "\n",
        "**Black-Box Nature**: Less interpretable than Word2Vec, making debugging or customization harder.\n",
        "\n",
        "\n",
        "**Please note that I am discussing the advantages and limitations of the particular models in general terms, not taking into account this homework particular case (as we already discussed it in detail).**\n",
        "\n",
        "**All the challenges I faced were discussed during the implementation. Mainly they were related to choosing hyperparameters and the parameters of model architectures (how we can make a model both good and not requiring a lot of time and resources).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
